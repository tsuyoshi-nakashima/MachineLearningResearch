- Abstract
  - 物体姿勢復元は、自律走行、ロボット工学、拡張現実などに関連する急速に発展する技術分野において重要な問題になっているため、コンピュータビジョン分野でますます注目を集めています。既存のレビュー関連の研究では、RGB画像中の注目オブジェクトの2Dバウンディングボックスを生成する方法を経て、2Dの視覚レベルでこの問題に取り組んでいる。2次元の探索空間は、RGB（モノ／ステレオ）画像と3次元空間の幾何情報を利用するか、LIDARセンサーやRGB-Dカメラからの奥行きデータを利用して拡大される。3次元バウンディングボックス検出器は、カテゴリレベルのアモーダルな3次元バウンディングボックスを生成し、重力アライメント画像で評価されるのに対し、完全な6次元物体姿勢推定器は、アライメント制約を除去した画像でインスタンスレベルでテストされることがほとんどである。近年、6次元物体姿勢推定はカテゴリレベルで取り組まれている。本論文では、3次元バウンディングボックス検出器から完全な6次元姿勢推定器まで、物体姿勢復元に関する手法の包括的かつ最新のレビューを初めて提示する。これらの手法は、問題を分類、回帰、分類と回帰、テンプレートマッチング、点対特徴量マッチングのタスクとして数学的にモデル化する。これに基づき、数学的モデルに基づく手法の分類が確立される。手法の評価に用いるデータセットについて、課題との関連性を調査し、評価指標を検討する。文献にある定量的な実験結果を分析し、どのカテゴリーの手法がどのような種類の課題に対して最も良い性能を発揮するかを示す。さらに、公開されている結果をより確かなものにするために、私たち自身の実装である2つの手法を比較し、分析を拡張しています。オブジェクトの姿勢回復に関して、この分野の現在の位置を要約し、可能な研究の方向性を明らかにする。

 - 物体の姿勢復元に関する研究を進める中で、2次元の視覚レベルにおける物体の姿勢復元を扱ったいくつかのレビュー関連論文[8,9,10,11,12,13,109,199]を目にした。これらの論文では、オクルージョン、クラッタ、テクスチャなどの課題が手法の性能に与える影響について議論されており、主にImageNet [6] やPASCAL [7] などの大規模データセットで評価されています。8]では、地理的コンテキスト、オブジェクトの空間的サポートなど、異なるコンテキストソースの2Dオブジェクト検出への影響が検討されている。Hoiemら[9]は、PASCALデータセットにおけるいくつかのベースラインの性能を評価し、特に偽陽性が仮定される理由を分析している。Torralbaら[11]は、関係するサンプル、データセット間の汎化、および相対的なデータの偏りに関して、いくつかのデータセットを比較しています。PASCALでは物体カテゴリが少ないため、Russakovskyら[10]はImageNetを用いてメタ分析を行い、色やテクスチャなどが物体検出器の性能に与える影響について調べています。また、PASCAL Visual Object Classes (VOC) ChallengeとImageNet Large Scale Visual Recognition Challengeをそれぞれ調査したretrospective evaluation [12] と benchmark [13] の研究は、2Dオブジェクトローカリゼーションとカテゴリ検出に関する最も包括的な分析を行っています。最近提案された研究[109]は、顕著なオブジェクト検出、顔検出、歩行者検出などのいくつかの特定のタスクを含む深層学習ベースのオブジェクト検出フレームワークを体系的にレビューしています。これらの研究は、一般化されたオブジェクト検出のための重要な意味を導入しているが、レビューされた方法と議論は、2Dの視覚レベルに限定されている。2D駆動型3Dバウンディングボックス（BB）検出法は、RGB画像とともに3D空間の利用可能な外観・幾何学情報を用いて2D探索空間を拡大する[90,151,153,154,144]。84,155]では、単眼RGB画像中の物体の3次元BBを、文脈モデルやセマンティクスを利用して直接検出する方法を示している。84,155]以外では、ステレオ画像[92]、RGB-Dカメラ[86,93,94,95,152]、LIDARセンサ[152]を入力として直接3D BBを検出する手法がある。また、複数のセンサ入力を融合し、3次元BBの仮説を生成する手法もいくつかある[107]。3次元BB検出法は、入力（RGB（Mo／St）、RGB-D、LIDAR）に依存せず、中心x＝（x，y，z）、サイズd＝（dw，dh，dl）、重力方向周りの向き（θy）でパラメータ化した配向性3次元BBを生成します。3次元BB検出器は6次元空間に拡張可能であるが、文献にある手法は主にKITTI [110], NYU-Depth v2 [111], SUN RGB-D [112] データセットで評価されており、関心対象が重力方向に整列しているものであることに注意。これらの手法は、データセットが要求するように、自動車、自転車、歩行者、椅子、ベッドなどのカテゴリレベルで動作し、アモーダル3D BB、すなわち、関心のあるオブジェクトを囲む最小の3D BBを生成する。

  - 物体の姿勢を復元するために考案された手法の探索空間は、さらに6次元に拡大され[165,171,175,183]、すなわち、3次元並進x = (x,y,z) と3次元回転 Θ = (θr,θp,θy) である。また、RGB-D画像から注目物体の6次元姿勢を推定する手法もある。全方位型テンプレートマッチング手法であるLinemod[2]は、色勾配と表面法線を用いて、乱雑な物体の6次元姿勢を推定するものである。この手法は、[24]において、識別学習により改良されている。FDCM [23]はロボット工学の応用に用いられている．Drostら[17]は、配向点対の特徴に基づくグローバルなモデル記述を作成し、高速な投票スキームを用いてそのモデルを局所的にマッチングさせる。さらに[43]では、この方法をクラッタやセンサノイズに対してより頑健にするために改良されている。潜在クラスハフフォレスト（LCHF）[4,26]は、1クラス学習を採用し、オクルージョンに対してロバスト性を提供するために、パーツベースのアプローチで表面の法線と色の勾配特徴を利用します。さらに、オクルージョンを考慮した特徴量[27]が定式化されている。また，[28,29]では，テクスチャのない物体を扱っている．さらに最近では、深層回路網（net）を用いて教師無しで特徴表現を学習する2 C. Sahin et al.／Image and Vision Computing 96 (2020) 103898 [35,36]. これらの手法は、RGBチャンネルと深度チャンネルからのデータを融合しているが、深度モダリティにおいては、局所的な信念伝搬に基づくアプローチ[73]と反復的洗練アーキテクチャ[31,32]が提案されている[74]。近年、RGB のみから 6 次元物体姿勢推定が実現されており[164,170,172,173,174,30,37,38,40]、現在のパラダイムは CNN の採用である [157,158,169]．BB8[40]やTekinら[38]は、角点回帰の後にPnPを行う。一般的には、反復最近点（ICP）や検証ネット（37）など、計算量の多い後処理が採用される。主にLINEMOD [2], OCCLUSION [28], LCHF [4], TLESS [42] データセットで評価されているように、完全6次元物体姿勢推定法は通常インスタンスのレベルで動作する。しかし、最近提案された手法[113,114]は、カテゴリレベルで6次元物体姿勢推定問題に取り組み、例えば、分布シフト、クラス内変動などの課題を扱っている[206]。本研究では、3次元BB検出器から完全な6次元姿勢推定器までの手法をレビューし、物体姿勢回復に関する包括的なレビューを行う。レビューされた手法は、分類、回帰、分類と回帰、テンプレートマッチング、および点対特徴マッチングタスクとして、オブジェクトの姿勢回復を数学的にモデル化しています。これに基づいて、数学的モデルに基づく手法の分類が確立され、5つの異なるカテゴリが形成される。さらに、各カテゴリ間の曖昧さをなくすため、進歩や欠点について研究している。文献にある個々のデータセットには、ある種の課題が含まれており、それに対して手法をテストすることで性能を測定することができる。視点変動、オクルージョン、クラッタ、クラス内変動、分布シフトなどの問題の課題は、オブジェクトの姿勢回復のために作成されたデータセットを調査することによって特定される。さらに、手法の性能を評価するために使用されるプロトコルについても検討する。レビューされた手法の分類を紹介し、問題の課題を特定したら、次に、課題に対する手法の性能を明らかにする。この目的のために、平均距離（AD）メトリック[2]の均一な採点基準の下で計算された、一般に入手可能なリコール値を分析する。さらに、ADに加えてVisible Surface Discrepancy (VSD)プロトコル[3]を使用した当社独自の実装である2つの手法[2,4]を比較して分析を拡張しています。この拡張は主に、公開された結果から得られた成果を活用し、この問題のあらゆる側面をつなぐ議論を完了させることを目的としています。最後に、物体姿勢回復に関するこの分野の現在の位置をまとめ、可能な研究の方向性を明らかにする。

  物体姿勢復元問題に対する手法は、物体姿勢パラメータである3次元移動x＝（x,y,z）と／3次元回転Θ＝（θr,θp,θy）を推定するものである。本論文では、問題のモデル化アプローチに基づいて、レビューされた方法を分類する。問題を分類タスクとして定式化し、ポーズパラメータを推定する手法は分類に含まれ、パラメータを回帰する手法は回帰に含まれる。分類と回帰は、分類と回帰の両方のタスクを組み合わせて、物体の3次元移動と3次元回転を推定する。テンプレートマッチング法は、特徴空間において、注釈付きテンプレートと表現されたテンプレートに一致する物体の姿勢パラメータを推定する方法である。点対特徴マッチング法は、任意の2点間の距離や法線間の角度などの関係を用いて、点対を表現する方法です。また、ハッシュテーブルと効率的な投票方式により、対象物体の姿勢パラメータを予測する。これらの5つの異なるモデリングアプローチ、分類、回帰、分類と回帰、テンプレートマッチング、点対特徴マッチングは、3Dから6Dまでのオブジェクト姿勢回復問題に対する最先端の手法をレビューするための識別的分類を形成しています。これらの手法を検討すると、2次元駆動型の3次元検出手法に遭遇することがある。2D駆動型3D手法は、例えば、R-CNN [115]、Fast R-CNN [116]、Faster RCNN [117]、R-FCN [118]、FPN [119]、YOLO [120]、SSD [121] 、GOP [122] またはMS-CNN [123] といった既製の2D検出器を利用してまず関心対象の2D BBs [156] を検出し、続いてこれを3D空間へ持ち上げ、したがってその性能が2D検出器に依存していることがわかる。さらに、その上に、オブジェクトの3次元並進／回転パラメータを直接生成する、いくつかの3次元検出器と完全な6次元姿勢推定器が構築されている。決定森（Decision Forest）[127]は、オブジェクトの姿勢回復の問題に対して重要である。手法の分類に入る前に、まず、いくつかの2次元検出器と決定森について簡単に言及する。R-CNN [115]は、入力RGB画像から、ボトムアップのグループ化と顕著性の手がかりに依存する選択的探索スキーム[124]を採用して、任意のサイズの領域提案の束を生成する。領域案は一定の解像度にワープされ、[125]のCNNアーキテクチャに供給され、CNN特徴ベクトルで表現される。各特徴ベクトルに対して、カテゴリ固有のSVMは、その領域がさらにBB回帰、および非最大抑制（NMS）フィルタリングで調整されるスコアを生成する。この3段階の処理により、R-CNNは、DPM HSC [126]などの従来の最良の2次元手法に対して約30%の改善を達成することができる。Fast R-CNN [116]は、RGB画像と領域提案の集合を入力とする。画像全体は、conv特徴マップを生成するために処理され、そこから固定長の特徴ベクトルが、各領域提案に対して生成される。各特徴ベクトルは、一連の完全連結（FC）層に供給され、最終的にソフトマックス分類とBB回帰の出口に分岐される。それぞれの学習用関心領域(RoI)には、真値クラスと真値回帰目標がラベル付けされる。Fast RCNNは各RoIに対してマルチタスク損失を導入し、分類とBB回帰のための共同学習を行う。

https://qiita.com/arutema47/items/8ff629a1516f7fd485f9

# 物体検出器のお話

## 大まかな流れ
物体がありそうな領域に対してCNNを回して物体認識する。CNN自体に時間がかかるからできる限りCNNの回数を減らしたい。

## R-CNN

## Fast-RCNN
R-CNNではROIに対して毎回CNNを回さなければいけなかった。
（流れ：RoIの算出→CNNで特徴マップ出力→クラス・BB算出）
一方でFast-RCNNは特徴マップとROIを入力としてクラス・BB算出をするため、CNNを回す回数が一回で済む。
（流れ：領域全体にCNNを回して特徴マップ取得。ROIは特徴マップに対して設定　→　FCLayerによってクラス・BBを算出）
ただしRegionProposalに時間がかかる問題は解決されておらず、大半がRegionProporsalに計算時間を要するため、RoI算出がボトルネックであることは変わらず。

## Faster-RCNN
RoIの算出をSelectiveSearchからCNNによる出力を入力としてRoIを抽出するモデルを追加した。RoIを提案するネットワークをRPN（RegionProposalNetwork）と呼んでいる。RoIの抽出にもCNNを使用することで速度改善を図ることに成功した。

## YOLO
Faster-RCNNではRPNでの計算自体が全体の計算処理におけるボトルネックになり、処理時間の遅延を招いている。（検出→識別を逐次処理で実行しているから）
YOLOでは検出と識別を同時に行うことがモチベーションになっている。（単一のネットワークアーキテクチャでE2Eで推論を実行する）
流れ
①画像をS×Sのグリッドセルに分割し、各グリッドセル内でB個のBoundingBoxを推定とConfidennceを算出
②また各グリッドセルの物体クラスそれぞれの条件付きクラス確立を算出
①、②の結果から信頼度スコアを算出し、どのBBoxが対象とするクラスの物体を正確に検出しているかを判断する。

## SSD
https://www.acceluniverse.com/blog/developers/2020/02/SSD.html

# 6DoF推定の話
## トレーニング方法
オフラインの段階で、分類器は合成データまたは実データに基づいて学習される。合成データは、対象物Oの3次元モデルMと、異なるカメラ視点からのRGB／D／RGB-D画像群を用いて生成される。3次元モデルMはCADでも再構成モデルでもよく、データの大きさを決める際には以下のような要素を考慮する。- 合理的な視点カバー率。対象物の合理的な視点範囲を捉えるために、半径が一定で細分化された正20面体の各頂点に仮想カメラを配置して合成画像を作成する。シナリオに応じて、正20面体の半球体や全球体を使用することができる。- オブジェクトの距離 合成画像は、対象物の位置する範囲によって異なるスケールでレンダリングされます。コンピュータグラフィックシステムは、正確なデータアノテーションを提供するため、分類ベースの手法では、これらのシステムで生成された合成データが使用される[88,81,89,27,28,29,33]。しかし、実写の画像に対して正確な物体の姿勢のアノテーションを得ることは困難であり、実写の学習データを用いた分類ベースの手法が存在する[28,29,33,77,88,89,96,104,149]。学習データは、姿勢パラメータ、すなわち、3次元移動x = (x,y,z), 3次元回転Θ = (θr,θp,θy)、またはその両方によって注釈される。学習データが生成されると、分類器は関連する損失関数を用いて学習される。

## 学習方法
オンライン段階での実際のテスト画像は、分類器による入力とされる。2D-driven3D法 [104,88,81] は、まず注目するオブジェクトの周囲の2D BBを抽出し（2D BB生成ブロック）、これを3Dにリフトアップさせる。入力によっては、[88,81,89,149,96,77,27]の方法は、入力画像に前処理を施し、3D仮説を生成する（入力前処理ブロック）。6次元物体姿勢推定器[27,28,29,33]は、入力画像から特徴を抽出し（特徴抽出ブロック）、学習した分類器を用いて、物体の6次元姿勢を推定する。さらに，学習された分類器の出力を洗練させ（洗練ブロック），フィルタリング後に最終的に物体の姿勢を推定する手法もある [104,81,149,28,29,33]．表 2 は，分類に基づく手法の詳細を示している．GS3D [104] は、2D画像に隠された3D情報を抽出し、正確な3D BB仮説を生成することに特化している。この手法は、Faster R-CNN [117]を改良し、2次元BBパラメータに加えて、RGB画像における回転θyを分類している。別のCNNアーキテクチャを利用し、x、d、θyをさらに分類し、オブジェクトのポーズパラメータを洗練させる。Paponら[88]は、複雑な乱雑なシーンにおける一般的な家具クラスの意味的なポーズを推定する。入力は強度(RGB)と表面法線(D)画像に変換される。2次元GOP検出器[122]を用いて2次元BB提案を生成し、これをさらにビンベースのクロスエントロピー損失Lceを用いてθyとzを分類して3次元空間へ持ち上げる。Guptaら[81]は、[76]から出力されたセグメント化された領域から開始し、その深度チャンネルは、表面法線画像を取得するためにさらに処理される。セグメント化された領域の回転θyは、Lce損失によって分類される。本手法は、さらに、オブジェクトのCADモデル上でICPを採用し、推定された粗いポーズを洗練させる。SVM-based Sliding Shapes (SS)[89]の入力深度画像は、ボクセル化された点群を得るために前処理される。この分類器は、ヒンジ損失 Lhinge を用いて、パラメータ x、d、θy を分類するために学習される。Renら[149]は，2次元の外観を3次元点群にリンクさせる Cloud of Oriented Gradients（COG）記述子を提案している．この方法は、3Dボックス提案を生成し、そのパラメータx、d、θyは、NMSフィルタリング後、さらに別の分類器（s-SVM）により洗練され、最終的な検出値を得ることができる。Wangら[96]は、点群の疎な性質を利用し、すべての推定物体位置の検索を可能にする投票スキームを採用しています。これは、LIDAR画像を3Dグリッドに変換した後、sSVMを使用してパラメータxを推定するものである。Wangら[96]と同様に、Vote3Deep[77]の入力LIDAR画像は、スパース3Dグリッドを取得するために前処理され、xおよびθyパラメータを分類するためにCNNアーキテクチャに供給される。3次元BB検出器の探索空間は、さらに6次元に拡大される[27,28,29,33]。ランダムフォレストに基づくBondeらの手法[27]は、オクルージョン、クラッタ、および類似した外観のディストラクタが同時に存在する奥行き画像において、オブジェクトの6次元姿勢を推定する。この方法は，情報利得 IG に基づいて学習され，Θを分類する．この手法は，3次元回転Θを分類するにもかかわらず，エッジレット特徴を抽出した後，シーンをボクセル化し，エッジレット特徴間の距離が最小となるボクセルの中心を検出物体の中心として選択する．Brachmannら[28]は、6次元物体姿勢推定問題に対するランダムフォレストに基づく手法を紹介している。この方法は、Bondeら[27]とは異なり、ICP-variantアルゴリズムを用いて、正確な6Dポーズを得る、関心のあるオブジェクトの3D並進パラメータxを分類するものである。Brachmannら[28]に基づいて、Krullら[29]とMichelら[33]は、6Dオブジェクトポーズ回復のための新しいRGB-Dベースの方法を提示する。29]と[33]の主な貢献は、絞り込みのステップにある。Krull ら[29]は観察とレンダリングの比較を学習する新しい CNN アーキテクチャを学習し， Michel ら[33]はポーズ仮説のプールを生成する新しい条件付きランダムフィールド（CRF） を設計している．これらの手法の学習段階は、[104,149,96,77]は実データに基づいており、[81,27]は合成画像を使って学習している。Papon ら[88]は合成画像に基づいて手法を学習しますが，さらに分類器を微調整するために実際のポジティブデータを利用し，未経験のインスタンスに対する手法の精度を向上させるヒューリスティックな手法を採用しています．Sliding Shapes [89] は、SVM を学習するために、ポジティブな合成画像とネガティブな実画像を使用しています。Brachmann ら[28]，それに伴い Krull ら[29]と Michel ら[33]は，正と負の実データ，正の合成データに基づいてフォレストを学習している．このうち、[88,89,149,96,77]で示される手法の仮説は、NMSフィルタリングされている。2D駆動の3D手法と3D手法はすべてカテゴリのレベルで動作する。完全な6Dポーズ推定器は、インスタンスレベルのオブジェクトポーズ推定用に設計されている。

